{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musixmatch Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests\n",
    "import requests\n",
    "import urllib\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "#data, strucuture and maths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import string\n",
    "from  more_itertools import unique_everseen\n",
    "import random\n",
    "\n",
    "#progress,performance and management\n",
    "from tqdm import tqdm_notebook\n",
    "import threading\n",
    "import os\n",
    "import ssl\n",
    "from IPython.display import clear_output\n",
    "import platform\n",
    "import os\n",
    "\n",
    "#time\n",
    "from time import sleep\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusixmatchScraper():\n",
    "    \n",
    "    \"\"\"This class allows you to scrape the lyrics for an artist who has a presence on Musixmatch\n",
    "    \n",
    "    An instance of the class needs to be instantiated with an artist URL e.g.\n",
    "    \n",
    "    https://www.musixmatch.com/artist/Bob-Dylan\n",
    "    \n",
    "    The default number of songs to scrape is 50\n",
    "    \n",
    "    Initiate scrape with self.Run()\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,artist_url,genre_label):\n",
    "\n",
    "        self.artist_url = artist_url #artists URL as attribute\n",
    "        \n",
    "        self.artist = artist_url.split('artist/')[-1] #artist string as attribute\n",
    "        \n",
    "        self.genre_label = genre_label\n",
    "         \n",
    "        self.song_l = [] #empty list to populate lyrics\n",
    "                        \n",
    "    def _get_html(self,url):\n",
    "        \n",
    "        \"\"\"Uses Beatiful Soup to extract html from a url. Returns a soup object \"\"\"\n",
    "\n",
    "        headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "\n",
    "        req = Request(url, headers=headers)\n",
    "\n",
    "        return BeautifulSoup(urlopen(req).read(), 'html.parser')\n",
    "\n",
    "    def _multithreadCompile(self,thread_count,iteration_list,func):\n",
    "        \n",
    "        \"\"\"a function that compiles an iteration list to prepare\n",
    "        multi threadding\"\"\"\n",
    "\n",
    "        jobs = []\n",
    "\n",
    "        #distribute iteration list to batches and append to jobs list\n",
    "        batches = [i.tolist() for i in np.array_split(iteration_list,thread_count)]\n",
    "\n",
    "        for i in range(len(batches)):\n",
    "\n",
    "            jobs.append(threading.Thread(target=func,args=[batches[i]]))\n",
    "            \n",
    "        return jobs\n",
    "\n",
    "    def _multithreadExecute(self,jobs):\n",
    "        \n",
    "        \"\"\"executes the multi-threadding loop\"\"\"\n",
    "\n",
    "        # Start the threads\n",
    "        for j in jobs:\n",
    "    \n",
    "            j.start()\n",
    "\n",
    "        # Ensure all of the threads have finished\n",
    "        for j in jobs:\n",
    "            j.join()\n",
    "        return\n",
    "    \n",
    "    def _getpageUrls(self,url):\n",
    "        \n",
    "        \"\"\"Gets all the links from an artist page\"\"\"\n",
    "     \n",
    "        html = self._get_html(url) #gets html for current page\n",
    "        \n",
    "        songs = html.find_all('h2',{'class':'media-card-title'}) #element for song\n",
    "        \n",
    "        #loop through and extract urls for all songs in soup object\n",
    "        song_urls = ['https://www.musixmatch.com'+i.find('a')['href'] for i in songs] \n",
    "        \n",
    "        #return list of song urls\n",
    "        return [i for i in song_urls if 'album' not in i]\n",
    "\n",
    "\n",
    "    def _getLyrics(self,song_url):\n",
    "        \n",
    "        \"\"\"Extracts lyrics from a song url. Duplicated lines are removed e.g. chorus lines\n",
    "        Only unique lyrics are returned\"\"\"\n",
    "    \n",
    "        html = self._get_html(song_url) #get html for current page\n",
    "\n",
    "        #find all elements containing lyrics\n",
    "        element = html.find_all('span',{'class':'lyrics__content__ok'})\n",
    "\n",
    "        #numbe of elements to loop through\n",
    "        element_loop = len(element)\n",
    "\n",
    "        song_lyrics = [] #empty list for song lyrics\n",
    "\n",
    "        #extract song lyrics\n",
    "        song_lyrics_raw = [element[i].text.split('\\n') for i in range(element_loop)]\n",
    "\n",
    "        #flatten list of lists\n",
    "        song_lyrics_raw = [i for sublist in song_lyrics_raw for i in sublist]\n",
    "\n",
    "        #retain only unique lines in lyrics\n",
    "        song_lyrics.extend(list(dict.fromkeys(song_lyrics_raw)))\n",
    "\n",
    "        #join list and remove empty elements\n",
    "        song_lyrics = ' '.join([i for i in song_lyrics if len(i) >0])\n",
    "\n",
    "        return song_lyrics #return song lyrics\n",
    "    \n",
    "    def _getAllpageUrls(self,target=50):\n",
    "        \n",
    "        \"\"\"Generates page urls for artist. There are 15 songs on each page\"\"\"\n",
    "        \n",
    "        loops = int(target/15) #specifcy how many loops needed\n",
    "        \n",
    "        #generate urls\n",
    "        artist_urls = [self.artist_url+'/'+str(i+1) for i in range(loops)]\n",
    "        \n",
    "        all_song_urls = [] #empty list for all song urls\n",
    "        \n",
    "        for i in artist_urls: #loop through and get all song urls for all pages\n",
    "            \n",
    "            all_song_urls.extend(self._getpageUrls(i))\n",
    "        \n",
    "        return all_song_urls\n",
    "              \n",
    "    def _extractData(self,all_song_urls):\n",
    "        \n",
    "        \"\"\"Extracts data from all song urls\"\"\"\n",
    "    \n",
    "        for i in tqdm_notebook(range(len(all_song_urls))): #loop through all song urls\n",
    "            \n",
    "            try:\n",
    "                #get lyrics\n",
    "                song_lyrics = self._getLyrics(all_song_urls[i])\n",
    "                \n",
    "                #get song title\n",
    "                song_title = all_song_urls[i].split('/')[-1]\n",
    "\n",
    "                #create DataFrame\n",
    "                song_df = pd.DataFrame([(self.artist,song_title,song_lyrics)],columns=['artist','song','lyrics'])\n",
    "                \n",
    "                #append DataFrame to master list\n",
    "                self.song_l.append(song_df)\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return \n",
    "    \n",
    "    def Run(self,target):\n",
    "        \n",
    "        \"\"\"Executes all methods above\"\"\"\n",
    "       \n",
    "        self.all_song_urls = self._getAllpageUrls(target) #get page URL's to get target number of songs\n",
    "\n",
    "        #multi-threaded scraping of all song urls\n",
    "        self._multithreadExecute(self._multithreadCompile(5,self.all_song_urls,self._extractData))\n",
    "\n",
    "        try:\n",
    "            df_final = pd.concat([i for i in self.song_l]) #concatenate all song Df's\n",
    "\n",
    "            df_final.reset_index(drop=True,inplace=True) #reset index\n",
    "            \n",
    "            self.df = df_final[df_final.lyrics.str.len() > 0] #drop any songs with no lyrics or failed scrapes\n",
    "\n",
    "            self.df['genre'] = self.genre_label\n",
    "            \n",
    "            return self.df\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            return\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
